{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f286bc31",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Oct  9 09:16:59 2025\n",
    "\n",
    "@author: jo_ht\n",
    "\"\"\"\n",
    "\n",
    "#neu's first code [09/08/2025]! yey\n",
    "\n",
    "# CELL 0: WORKFLOW OVERVIEW\n",
    "# --------------------------\n",
    "# This Jupyter Notebook automates preparing of CSV files from TCRM for comparison to ecmwf_env data\n",
    "# for multiple tropical cyclones (TCs).\n",
    "\n",
    "# Workflow:\n",
    "# A. CELL 1 & 2: Cleaning CSVs to remove rows with missing values in specific columns (_filtered CSVs)\n",
    "# B. CELL 3: Run cleaning across all CSVs and subfolders\n",
    "#      - input_base  (folder with raw CSVs)\n",
    "#      - columns_to_check  (columns to filter, can use letters)\n",
    "\n",
    "# C. CELL 4: List all _filtered CSV files for verification\n",
    "# 4. CELL 5: Function to reorder CSV rows based on specified columns (creates _reordered CSVs)\n",
    "# 5. # CELL 6a: IDENTIFY _FILTERED FOLDER\n",
    "#    - filtered_folder  (optional manual override)\n",
    "\n",
    "# CELL 6b: CREATE _EDITED FOLDER STRUCTURE\n",
    "#    - main_output_folder  (folder path/name)\n",
    "\n",
    "# CELL 6d: REORDER CSVS\n",
    "#    - reorder_by_letters  (columns to reorder/group by)      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe531612",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# CELL 1: IMPORT LIBRARIES\n",
    "# ------------------------\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c0406e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# CELL 2: CLEANING FUNCTION (Recursive + Only Process MonthDate CSVs)\n",
    "# -------------------------------------------------------------------\n",
    "# Purpose:\n",
    "#   - Recursively scan all subfolders under folder_path\n",
    "#   - Process only CSV files containing a month+date segment (e.g., \"_Jul23_\")\n",
    "#   - Skip any CSVs with \"_DayN\" in their names\n",
    "#   - Drop rows with missing values in specified columns\n",
    "#   - Save filtered files with \"_filtered\" appended\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def clean_folder(folder_path, columns_to_check):\n",
    "    \"\"\"\n",
    "    Recursively reads all CSV files under folder_path that:\n",
    "      ‚úÖ Contain a month+date pattern like '_Jul23_'\n",
    "      ‚ùå Do NOT contain '_DayN'\n",
    "    Removes rows with missing values in columns_to_check\n",
    "    and saves filtered versions with '_filtered' appended.\n",
    "    \"\"\"\n",
    "    # Pattern: underscores + 3-letter month + 2-digit day + underscore\n",
    "    month_pattern = re.compile(r\"_[A-Za-z]{3}\\d{2}_\")  # e.g., \"_Jul23_\"\n",
    "\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if not file.endswith(\".csv\"):\n",
    "                continue  # process only CSV\n",
    "\n",
    "            # ‚ùå Skip DayN files (e.g., \"_Day1\", \"_Day12\")\n",
    "            if re.search(r\"_Day\\d+\", file):\n",
    "                print(f\"Skipping Day file: {file}\")\n",
    "                continue\n",
    "\n",
    "            # ‚úÖ Only process files with \"_MonDD_\" in filename\n",
    "            if not month_pattern.search(file):\n",
    "                print(f\"Skipping (no valid month+date): {file}\")\n",
    "                continue\n",
    "\n",
    "            input_file = os.path.join(root, file)\n",
    "            print(f\"\\nProcessing: {input_file}\")\n",
    "\n",
    "            try:\n",
    "                # Read CSV\n",
    "                df = pd.read_csv(input_file)\n",
    "\n",
    "                # Drop rows with missing values in specified columns\n",
    "                df_cleaned = df.dropna(subset=columns_to_check)\n",
    "\n",
    "                # Save filtered version next to original\n",
    "                base, ext = os.path.splitext(file)\n",
    "                output_file = os.path.join(root, f\"{base}_filtered{ext}\")\n",
    "                df_cleaned.to_csv(output_file, index=False)\n",
    "\n",
    "                print(f\"  ‚Üí Filtered file saved as: {output_file}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"  ‚ö†Ô∏è Failed to process {file}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e6706a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# CELL 3: RUN CLEANING (Recursive CSV only, skip Day files)\n",
    "# --------------------------------------------------------\n",
    "# Purpose: Recursively scan all subfolders under `input_base`,\n",
    "# filter only valid CSVs (with \"_MonDD\"), ignore \"_DayN\",\n",
    "# drop rows with missing K/L, and save to mirrored \"_filtered\" tree.\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# --- USER CONFIG ---\n",
    "input_base = r\"C:\\Users\\jo_ht\\OneDrive\\Documents\\neu\\sept 22 report\\tcrm\\swiftph output csv\"\n",
    "columns_to_check = [\"K\", \"L\"]\n",
    "designated_dir = r\"C:\\Users\\jo_ht\\OneDrive\\Documents\\neu\\sept 22 report\\tcrm\\tcrm_edit data\"\n",
    "\n",
    "# --- Patterns ---\n",
    "month_pattern = re.compile(r\"_[A-Z][a-z]{2}\\d{2}\")   # e.g. _Jul23\n",
    "day_pattern = re.compile(r\"_Day\\d+\", re.IGNORECASE)  # e.g. _Day0\n",
    "\n",
    "# --- Detect TC name + year from a valid CSV ---\n",
    "example_file = None\n",
    "for root, _, files in os.walk(input_base):\n",
    "    for f in files:\n",
    "        if f.lower().endswith(\".csv\") and month_pattern.search(f) and not day_pattern.search(f):\n",
    "            example_file = f\n",
    "            break\n",
    "    if example_file:\n",
    "        break\n",
    "\n",
    "if example_file:\n",
    "    parts = example_file.split(\"_\")\n",
    "    tc_name = parts[0]\n",
    "    yy = parts[1][-2:]\n",
    "    output_folder_name = f\"{tc_name}_20{yy}_filtered\"\n",
    "else:\n",
    "    output_folder_name = \"_filtered\"\n",
    "\n",
    "# --- Create output root ---\n",
    "output_base = os.path.join(designated_dir, output_folder_name)\n",
    "os.makedirs(output_base, exist_ok=True)\n",
    "print(f\"Filtered CSVs will be saved to: {output_base}\")\n",
    "\n",
    "# --- Recursive processing ---\n",
    "for root, _, files in os.walk(input_base):\n",
    "    relative_path = os.path.relpath(root, input_base)\n",
    "    out_subfolder = os.path.join(output_base, relative_path)\n",
    "    os.makedirs(out_subfolder, exist_ok=True)\n",
    "\n",
    "    for file in files:\n",
    "        # Only CSV files\n",
    "        if not file.lower().endswith(\".csv\"):\n",
    "            continue\n",
    "\n",
    "        # Skip \"_DayN\" CSVs\n",
    "        if day_pattern.search(file):\n",
    "            print(f\"Skipping Day file: {file}\")\n",
    "            continue\n",
    "\n",
    "        # Process only if filename contains \"_MonDD\"\n",
    "        if not month_pattern.search(file):\n",
    "            print(f\"Skipping (no _MonDD): {file}\")\n",
    "            continue\n",
    "\n",
    "        input_file = os.path.join(root, file)\n",
    "        print(f\"Processing: {input_file}\")\n",
    "\n",
    "        # Load CSV\n",
    "        try:\n",
    "            df = pd.read_csv(input_file)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to read {input_file}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Drop rows with missing K/L\n",
    "        col_indices = [ord(c.upper()) - ord(\"A\") for c in columns_to_check]\n",
    "        valid_cols = [df.columns[i] for i in col_indices if i < len(df.columns)]\n",
    "        df_filtered = df.dropna(subset=valid_cols)\n",
    "\n",
    "        # Save filtered file\n",
    "        base, ext = os.path.splitext(file)\n",
    "        output_file = os.path.join(out_subfolder, f\"{base}_filtered{ext}\")\n",
    "        try:\n",
    "            df_filtered.to_csv(output_file, index=False)\n",
    "            print(f\"Saved: {output_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to save {output_file}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4dc8dc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# CELL 4: LIST FILTERED FILES\n",
    "# Purpose: Verify all _filtered CSVs are created, especially useful for multiple TCs\n",
    "\n",
    "for root, dirs, files in os.walk(input_base):\n",
    "    for file in files:\n",
    "        if file.endswith(\"_filtered.csv\"):\n",
    "            print(os.path.join(root, file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d801ec96",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# CELL 5: REORDERING TOOL\n",
    "# -----------------------\n",
    "# Purpose: Reorder rows of filtered CSVs based on specified columns (letters)\n",
    "# Creates _reordered CSVs; empty CSVs are still processed\n",
    "\n",
    "def reorder_all_csv(input_base, output_base, reorder_by_letters):\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    \n",
    "    os.makedirs(output_base, exist_ok=True)\n",
    "\n",
    "    for root, dirs, files in os.walk(input_base):\n",
    "        csv_files = [f for f in files if f.lower().endswith(\".csv\")]\n",
    "        if not csv_files:\n",
    "            continue\n",
    "\n",
    "        for file in csv_files:\n",
    "            input_file = os.path.join(root, file)\n",
    "            print(f\"\\nProcessing: {input_file}\")\n",
    "\n",
    "            try:\n",
    "                df = pd.read_csv(input_file)\n",
    "            except Exception as e:\n",
    "                print(f\"  ‚ö† Failed to read {input_file}: {e}\")\n",
    "                continue\n",
    "\n",
    "            if not df.empty:\n",
    "                # Convert letters to column names\n",
    "                col_indices = [ord(c.upper()) - ord(\"A\") for c in reorder_by_letters]\n",
    "                cols = [df.columns[i] for i in col_indices if 0 <= i < len(df.columns)]\n",
    "                if cols:\n",
    "                    df = df.sort_values(by=cols).reset_index(drop=True)\n",
    "\n",
    "            base, ext = os.path.splitext(file)\n",
    "            output_file = os.path.join(output_base, f\"{base}_reordered{ext}\")\n",
    "            try:\n",
    "                df.to_csv(output_file, index=False)\n",
    "                print(f\"  ‚Üí Reordered file saved as {output_file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  ‚ö† Failed to write {output_file}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0914b1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# CELL 6a: LOCATE _FILTERED FOLDER\n",
    "import os\n",
    "\n",
    "# üëá EDIT if needed\n",
    "main_folder = r\"C:\\Users\\jo_ht\\OneDrive\\Documents\\neu\\sept 22 report\\tcrm\\tcrm_edit data\"  # folder containing raw subfolders\n",
    "\n",
    "# Automatically detect the _filtered folder\n",
    "filtered_folder = None\n",
    "for f in os.listdir(main_folder):\n",
    "    full_path = os.path.join(main_folder, f)\n",
    "    if os.path.isdir(full_path) and f.endswith(\"_filtered\"):\n",
    "        filtered_folder = full_path\n",
    "        break\n",
    "\n",
    "if not filtered_folder:\n",
    "    raise FileNotFoundError(\"No _filtered folder found in main_folder!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7676b6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# CELL 6B: CREATE _REORDERED FOLDER\n",
    "# üëá Create _reordered folder using same TC name + year as _filtered\n",
    "reordered_base = filtered_folder.replace(\"_filtered\", \"_reordered\")\n",
    "os.makedirs(reordered_base, exist_ok=True)\n",
    "\n",
    "print(f\"üìÇ Reordered files will be saved in: {reordered_base}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0b4d22",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# CELL 6c: REORDER CSV FILES (all subfolders, no duplication)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# üëá EDITABLE: columns to reorder by (letters)\n",
    "reorder_by_letters = [\"C\", \"E\", \"G\", \"K\", \"L\"]\n",
    "\n",
    "# Traverse all subfolders in _filtered\n",
    "for root, dirs, files in os.walk(filtered_folder):\n",
    "    rel_path = os.path.relpath(root, filtered_folder)\n",
    "    output_subfolder = os.path.join(reordered_base, rel_path)\n",
    "    os.makedirs(output_subfolder, exist_ok=True)\n",
    "\n",
    "    for file in files:\n",
    "        if file.lower().endswith(\".csv\"):\n",
    "            input_file = os.path.join(root, file)\n",
    "            df = pd.read_csv(input_file)\n",
    "\n",
    "            if df.empty:\n",
    "                print(f\"‚ö†Ô∏è Empty file: {file} ‚Üí still saved as _reordered\")\n",
    "            else:\n",
    "                # üîπ Rename Pro_Name ‚Üí prov for consistency\n",
    "                df = df.rename(columns={\"Pro_Name\": \"prov\"})\n",
    "\n",
    "                # Convert letters to column names safely\n",
    "                col_indices = [ord(c.upper()) - ord(\"A\") for c in reorder_by_letters]\n",
    "                cols = [df.columns[i] for i in col_indices if 0 <= i < len(df.columns)]\n",
    "\n",
    "                if cols:\n",
    "                    sort_orders = []\n",
    "                    for col in cols:\n",
    "                        if pd.api.types.is_numeric_dtype(df[col]):\n",
    "                            sort_orders.append(False)  # descending for numbers\n",
    "                        else:\n",
    "                            sort_orders.append(True)   # ascending for text\n",
    "\n",
    "                    try:\n",
    "                        df = df.sort_values(by=cols, ascending=sort_orders, na_position=\"last\").reset_index(drop=True)\n",
    "                    except Exception as e:\n",
    "                        print(f\"‚ö†Ô∏è Could not reorder {file} by {cols}: {e}\")\n",
    "\n",
    "            # Save with \"_reordered\" suffix instead of \"_filtered\"\n",
    "            output_file = os.path.join(\n",
    "                output_subfolder, file.replace(\"_filtered\", \"_reordered\")\n",
    "            )\n",
    "            df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50071d2e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# CELL 7: PROVINCE-LEVEL AGGREGATION (Fixed Output Path)\n",
    "# ------------------------------------------------------\n",
    "# Purpose: Aggregate municipality-level mean_ctrl and wtd_mean values\n",
    "#          into province-level averages.\n",
    "# Output:  Always saved under the fixed \"_aggregated\" folder:\n",
    "#          C:\\Users\\jo_ht\\OneDrive\\Documents\\neu\\sept 22 report\\tcrm\\tcrm_edit data\\_aggregated\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Input = reordered folder from Cell 6\n",
    "input_base = reordered_base  \n",
    "\n",
    "# ‚úÖ Fixed aggregated output path\n",
    "aggregated_base = r\"C:\\Users\\jo_ht\\OneDrive\\Documents\\neu\\sept 22 report\\tcrm\\tcrm_edit data\\_aggregated\"\n",
    "os.makedirs(aggregated_base, exist_ok=True)\n",
    "\n",
    "print(f\"üìÇ Aggregated province-level files will be saved in: {aggregated_base}\")\n",
    "\n",
    "required_cols = {\"prov\", \"mean_ctrl\", \"wtd_mean\"}\n",
    "\n",
    "for root, dirs, files in os.walk(input_base):\n",
    "    rel_path = os.path.relpath(root, input_base)\n",
    "    output_subfolder = os.path.join(aggregated_base, rel_path)\n",
    "    os.makedirs(output_subfolder, exist_ok=True)\n",
    "\n",
    "    for file in files:\n",
    "        if not file.lower().endswith(\".csv\"):\n",
    "            continue\n",
    "\n",
    "        input_file = os.path.join(root, file)\n",
    "        try:\n",
    "            df = pd.read_csv(input_file)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö† Failed to read {input_file}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Skip empty or incomplete files\n",
    "        if df.empty or not required_cols.issubset(df.columns):\n",
    "            continue\n",
    "\n",
    "        # Province-level aggregation\n",
    "        province_agg = (\n",
    "            df.groupby(\"prov\")[[\"mean_ctrl\", \"wtd_mean\"]]\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        # Rename headers only in aggregated CSVs\n",
    "        province_agg = province_agg.rename(\n",
    "            columns={\n",
    "                \"mean_ctrl\": \"mean_ctrl (TCRM)\",\n",
    "                \"wtd_mean\": \"wtd_mean (TCRM)\"\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Save to the fixed aggregated folder (preserving relative subfolder structure)\n",
    "        output_file = os.path.join(output_subfolder, file.replace(\"_reordered\", \"_aggregated\"))\n",
    "        try:\n",
    "            province_agg.to_csv(output_file, index=False)\n",
    "            print(f\"‚úÖ Created aggregated file: {output_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö† Failed to save {output_file}: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
